model_list:
  - model_name: gpt-oss-20b
    litellm_params:
      model: openai/gpt-oss-20b
      api_base: http://llama:8080/v1
      api_key: placeholder
  
  - model_name: gpt-oss-120b
    litellm_params:
      model: openai/gpt-oss-120b
      api_base: http://llama:8080/v1
      api_key: placeholder
      # Added because Claude Code sends reasoning_effort which isn't marked as supported
      # Should probably look into fixing that or at least explicitly permitting that param so that this won't silently drop other params
      drop_params: true
  
  - model_name: Qwen3-30B
    litellm_params:
      model: openai/Qwen3-30B
      api_base: http://llama:8080/v1
      api_key: placeholder
  
  - model_name: Qwen3-Coder-30B
    litellm_params:
      model: openai/Qwen3-Coder-30B
      api_base: http://llama:8080/v1
      api_key: placeholder
  
  - model_name: flux-2-klein-4b
    litellm_params:
      model: openai/flux-2-klein-4b
      api_base: http://llama:8080/v1
      api_key: placeholder
      # Added because LiteLLM claims this doesn't support response_format even though it actually does
      drop_params: true
    model_info:
      mode: image_generation
