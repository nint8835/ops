# generated by datamodel-codegen:
#   filename:  https://raw.githubusercontent.com/mostlygeek/llama-swap/refs/heads/main/config-schema.json
#   timestamp: 2026-01-17T23:42:07+00:00

from __future__ import annotations

from enum import Enum
from typing import Any

from pydantic import AnyUrl, BaseModel, ConfigDict, Field, RootModel, conint, constr


class LogLevel(Enum):
    debug = "debug"
    info = "info"
    warn = "warn"
    error = "error"


class LogTimeFormat(Enum):
    field_ = ""
    ansic = "ansic"
    unixdate = "unixdate"
    rubydate = "rubydate"
    rfc822 = "rfc822"
    rfc822z = "rfc822z"
    rfc850 = "rfc850"
    rfc1123 = "rfc1123"
    rfc1123z = "rfc1123z"
    rfc3339 = "rfc3339"
    rfc3339nano = "rfc3339nano"
    kitchen = "kitchen"
    stamp = "stamp"
    stampmilli = "stampmilli"
    stampmicro = "stampmicro"
    stampnano = "stampnano"


class Filters(BaseModel):
    model_config = ConfigDict(
        extra="forbid",
    )
    stripParams: constr(pattern=r"^[a-zA-Z0-9_, ]*$") | None = Field(
        "",
        description="Comma separated list of parameters to remove from the request. Used for server-side enforcement of sampling parameters.",
    )
    setParams: dict[str, Any] | None = Field(
        {},
        description="Dictionary of parameters to set/override in requests. Useful for enforcing specific parameter values. Protected params like 'model' cannot be overridden. Values can be strings, numbers, booleans, arrays, or objects.",
    )


class Groups(BaseModel):
    swap: bool | None = Field(
        True,
        description="Controls model swapping behaviour within the group. True: only one model runs at a time. False: all models can run together.",
    )
    exclusive: bool | None = Field(
        True,
        description="Controls how the group affects other groups. True: causes all other groups to unload when this group runs a model. False: does not affect other groups.",
    )
    persistent: bool | None = Field(
        False,
        description="Prevents other groups from unloading the models in this group. Does not affect individual model behaviour.",
    )
    members: list[str] = Field(
        ...,
        description="Array of model IDs that are members of this group. Model IDs must be defined in models.",
    )


class OnStartup(BaseModel):
    model_config = ConfigDict(
        extra="forbid",
    )
    preload: list[str] | None = Field(
        [],
        description="List of model IDs to load on startup. Model names must match keys in models. When preloading multiple models, define a group to prevent swapping.",
    )


class Hooks(BaseModel):
    model_config = ConfigDict(
        extra="forbid",
    )
    on_startup: OnStartup | None = Field(
        None,
        description="Actions to perform on startup. Only supported action is preload.",
    )


class LogToStdout(Enum):
    proxy = "proxy"
    upstream = "upstream"
    both = "both"
    none = "none"


class Filters1(BaseModel):
    model_config = ConfigDict(
        extra="forbid",
    )
    stripParams: constr(pattern=r"^[a-zA-Z0-9_, ]*$") | None = Field(
        "",
        description="Comma separated list of parameters to remove from the request. Useful for removing parameters that the peer doesn't support.",
    )
    setParams: dict[str, Any] | None = Field(
        {},
        description="Dictionary of parameters to set/override in requests to this peer. Useful for injecting provider-specific settings. Protected params like 'model' cannot be overridden. Values can be strings, numbers, booleans, arrays, or objects.",
    )


class Peers(BaseModel):
    proxy: AnyUrl = Field(
        ...,
        description="A valid base URL to proxy requests to. Requested path to llama-swap will be appended to the end of the proxy value.",
    )
    apiKey: str | None = Field(
        "",
        description="A string key to be injected into the request. If blank, no key will be added. Key will be injected into headers: Authorization: Bearer <key> and x-api-key: <key>.",
    )
    models: list[constr(min_length=1)] = Field(
        ..., description="A list of models served by the peer."
    )
    filters: Filters1 | None = Field(
        default_factory=lambda: Filters1.model_validate({}),
        description="Dictionary of filter settings for peer requests. Supports stripParams and setParams.",
    )


class Macros(
    RootModel[
        dict[
            constr(pattern=r"^[a-zA-Z0-9_-]+$", min_length=1, max_length=64),
            constr(min_length=0, max_length=1024) | float | bool,
        ]
    ]
):
    root: dict[
        constr(pattern=r"^[a-zA-Z0-9_-]+$", min_length=1, max_length=64),
        constr(min_length=0, max_length=1024) | float | bool,
    ] = Field(
        {},
        description="A dictionary of string substitutions. Macros are reusable snippets used in model cmd, cmdStop, proxy, checkEndpoint, filters.stripParams. Macro names must be <64 chars, match ^[a-zA-Z0-9_-]+$, and not be PORT or MODEL_ID. Values can be string, number, or boolean. Macros can reference other macros defined before them.",
    )


class Models(BaseModel):
    macros: Macros | None = Field(default_factory=lambda: Macros({}))
    cmd: constr(min_length=1) = Field(
        ...,
        description="Command to run to start the inference server. Macros can be used. Comments allowed with |.",
    )
    cmdStop: str | None = Field(
        "",
        description="Command to run to stop the model gracefully. Uses ${PID} macro for upstream process id. If empty, default shutdown behavior is used.",
    )
    name: constr(max_length=128) | None = Field(
        "", description="Display name for the model. Used in v1/models API response."
    )
    description: constr(max_length=1024) | None = Field(
        "", description="Description for the model. Used in v1/models API response."
    )
    env: list[constr(pattern=r"^[A-Z_][A-Z0-9_]*=.*$")] | None = Field(
        [],
        description="Array of environment variables to inject into cmd's environment. Each value is a string in ENV_NAME=value format.",
    )
    proxy: AnyUrl | None = Field(
        "http://localhost:${PORT}",
        description="URL where llama-swap routes API requests. If custom port is used in cmd, this must be set.",
    )
    aliases: list[constr(min_length=1)] | None = Field(
        [],
        description="Alternative model names for this configuration. Must be unique globally.",
    )
    checkEndpoint: constr(pattern=r"^/.*$|^none$") | None = Field(
        "/health",
        description="URL path to check if the server is ready. Use 'none' to skip health checking.",
    )
    ttl: conint(ge=0) | None = Field(
        0,
        description="Automatically unload the model after ttl seconds. 0 disables unloading. Must be >0 to enable.",
    )
    useModelName: str | None = Field(
        "",
        description="Override the model name sent to upstream server. Useful if upstream expects a different name.",
    )
    filters: Filters | None = Field(
        default_factory=lambda: Filters.model_validate({}),
        description="Dictionary of filter settings. Supports stripParams and setParams.",
    )
    metadata: dict[str, Any] | None = Field(
        {},
        description="Dictionary of arbitrary values included in /v1/models. Can contain complex types. Only passed through in /v1/models responses.",
    )
    concurrencyLimit: conint(ge=0) | None = Field(
        0,
        description="Overrides allowed number of active parallel requests to a model. 0 uses internal default of 10. >0 overrides default. Requests exceeding limit get HTTP 429.",
    )
    sendLoadingState: bool | None = Field(
        None,
        description="Overrides the global sendLoadingState for this model. Ommitting this property will use the global setting.",
    )
    unlisted: bool | None = Field(
        False,
        description="If true the model will not show up in /v1/models responses. It can still be used as normal in API requests.",
    )


class LlamaSwapConfiguration(BaseModel):
    healthCheckTimeout: conint(ge=15) | None = Field(
        120,
        description="Number of seconds to wait for a model to be ready to serve requests.",
    )
    logLevel: LogLevel | None = Field(
        "info",
        description="Sets the logging value. Valid values: debug, info, warn, error.",
    )
    logTimeFormat: LogTimeFormat | None = Field(
        "",
        description='Enables and sets the logging timestamp format. Valid values: "", "ansic", "unixdate", "rubydate", "rfc822", "rfc822z", "rfc850", "rfc1123", "rfc1123z", "rfc3339", "rfc3339nano", "kitchen", "stamp", "stampmilli", "stampmicro", and "stampnano". For more info, read: https://pkg.go.dev/time#pkg-constants',
    )
    metricsMaxInMemory: int | None = Field(
        1000,
        description="Maximum number of metrics to keep in memory. Controls how many metrics are stored before older ones are discarded.",
    )
    startPort: int | None = Field(
        5800,
        description="Starting port number for the automatic ${PORT} macro. The ${PORT} macro is incremented for every model that uses it.",
    )
    sendLoadingState: bool | None = Field(
        False,
        description="Inject loading status updates into the reasoning field. When true, a stream of loading messages will be sent to the client.",
    )
    includeAliasesInList: bool | None = Field(
        False,
        description="Present aliases within the /v1/models OpenAI API listing. when true, model aliases will be output to the API model listing duplicating all fields except for Id so chat UIs can use the alias equivalent to the original.",
    )
    macros: Macros | None = Field(default_factory=lambda: Macros({}))
    models: dict[str, Models] = Field(
        ...,
        description="A dictionary of model configurations. Each key is a model's ID. Model settings have defaults if not defined. The model's ID is available as ${MODEL_ID}.",
    )
    groups: dict[str, Groups] | None = Field(
        None,
        description="A dictionary of group settings. Provides advanced controls over model swapping behaviour. Model IDs must be defined in models. A model can only be a member of one group. Behaviour controlled via swap, exclusive, persistent.",
    )
    hooks: Hooks | None = Field(
        None,
        description="A dictionary of event triggers and actions. Only supported hook is on_startup.",
    )
    logToStdout: LogToStdout | None = Field(
        "proxy",
        description="Controls what is logged to stdout. 'proxy': logs generated by llama-swap, 'upstream': copy of upstream process stdout logs, 'both': both interleaved together, 'none': no logs written to stdout.",
    )
    apiKeys: list[constr(min_length=1)] | None = Field(
        [],
        description="Require an API key when making requests to inference endpoints. When empty, authorization will not be checked. Each key is a non-empty string.",
    )
    peers: dict[str, Peers] | None = Field(
        default_factory=lambda: Peers.model_validate({}),
        description="A dictionary of remote peers and models they provide. Peers can be another llama-swap or any server that provides the /v1/ generative API endpoints supported by llama-swap.",
    )
